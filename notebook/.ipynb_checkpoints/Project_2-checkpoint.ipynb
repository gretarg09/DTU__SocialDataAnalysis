{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets start by getting the data\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "data = []\n",
    "\n",
    "def process(IncidntNum,Category,Descript,DayOfWeek,Data,Time,PdDistrict,Resolution,Address,X,Y,Location,PdId):\n",
    "    data.append({\n",
    "            \"IncidntNum\":IncidntNum,\n",
    "            \"Category\":Category,\n",
    "            \"Descript\":Descript,\n",
    "            \"DayOfWeek\":DayOfWeek,\n",
    "            \"Date\":Date,\n",
    "            \"Time\":Time,\n",
    "            \"PdDistrict\":PdDistrict,\n",
    "            \"Resolution\":Resolution,\n",
    "            \"Address\":Address,\n",
    "            \"X\":X,\n",
    "            \"Y\":Y,\n",
    "            \"Location\":Location,\n",
    "            \"PdId\":PdId})\n",
    "\n",
    "with open(\"SFPD_Incidents_-_from_1_January_2003.csv\", \"rb\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile,delimiter=\",\")\n",
    "    for row in reader:\n",
    "        IncidntNum = row[\"IncidntNum\"]\n",
    "        Category = row[\"Category\"]\n",
    "        Descript = row[\"Descript\"]\n",
    "        DayOfWeek = row[\"DayOfWeek\"]\n",
    "        Date = row[\"Date\"]\n",
    "        Time = row[\"Time\"]\n",
    "        PdDistrict = row[\"PdDistrict\"]\n",
    "        Resolution = row[\"Resolution\"]\n",
    "        Address = row[\"Address\"]\n",
    "        X = row[\"X\"]\n",
    "        Y = row[\"Y\"]\n",
    "        Location = row[\"Location\"]\n",
    "        PdId = row[\"PdId\"]\n",
    "        process(IncidntNum,Category,Descript,DayOfWeek,Date,Time,PdDistrict,Resolution,Address,X,Y,Location,PdId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_from_district(district_data, name):\n",
    "    nr_of_prostitution = len([line for line in district_data if line == \"PROSTITUTION\"])\n",
    "    nr_of_vehicle_theft = len([line for line in district_data if line == \"VEHICLE THEFT\"])\n",
    "    total_nr_of_crime = len(district_data)\n",
    "    return {\"District\":name, \"total\":total_nr_of_crime, \"vehicle\":nr_of_vehicle_theft, \"prostitution\":nr_of_prostitution}\n",
    "\n",
    "pdDistrict = set([line[\"PdDistrict\"] for line in data])\n",
    "    \n",
    "data_parsed = {\n",
    "    \"Period2003\":[],\n",
    "    \"Period2015\":[]\n",
    "}\n",
    "\n",
    "data_from_2015 = [{\"Category\":line[\"Category\"], \"PdDistrict\":line[\"PdDistrict\"]} for line in data if int(line[\"Date\"].split(\"/\")[-1]) == 2015]\n",
    "nr_of_crimes_2015 = len(data_from_2015)\n",
    "\n",
    "data_from_2003 = [{\"Category\":line[\"Category\"], \"PdDistrict\":line[\"PdDistrict\"]} for line in data if int(line[\"Date\"].split(\"/\")[-1]) == 2003]\n",
    "nr_of_crimes_2003 = len(data_from_2003)\n",
    " \n",
    "for district in pdDistrict:\n",
    "    data_for_district_2015 = [line[\"Category\"] for line in data_from_2015 if line[\"PdDistrict\"] == district]\n",
    "    data_parsed[\"Period2015\"].append(get_data_from_district(data_for_district_2015,district))\n",
    "    data_for_district_2003 = [line[\"Category\"] for line in data_from_2003 if line[\"PdDistrict\"] == district]\n",
    "    data_parsed[\"Period2003\"].append(get_data_from_district(data_for_district_2003,district))\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data1.json', 'w') as fp:\n",
    "    json.dump(data_parsed, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the data on correct format\n",
    "data_prostitution_location = {\n",
    "    \"lat\":[], \n",
    "    \"lon\":[] \n",
    "}\n",
    "\n",
    "for line in data:\n",
    "    if line[\"Category\"] == \"PROSTITUTION\":\n",
    "        latitute,longitute = line[\"Location\"].split(\",\")\n",
    "        latitute = float(latitute[1:])\n",
    "        longitute = float(longitute[:-1])\n",
    "        if float(latitute) < 90.00:\n",
    "            data_prostitution_location[\"lat\"].append(latitute)\n",
    "            data_prostitution_location[\"lon\"].append(longitute)\n",
    "\n",
    "kmeans_error = []\n",
    "kmeans_labels = []\n",
    "iterate = [i+2 for i in range(5)]\n",
    "\n",
    "# Get the data on correct format for sklearn.cluster.kmeans\n",
    "location_input = np.array(zip(data_prostitution_location[\"lat\"],data_prostitution_location[\"lon\"]))\n",
    "\n",
    "for i in iterate:\n",
    "    kMeans_ = KMeans(n_clusters=i, random_state=0).fit(location_input)\n",
    "    kmeans_data[\"labels_knn{}\".format(i)] = list(kMeans_.labels_)\n",
    "    kmeans_error.append(kMeans_.inertia_)\n",
    "    kmeans_labels.append(kMeans_.labels_)\n",
    "\n",
    "kmeans_data3 =  {\n",
    "    \"knn2\" : {\n",
    "        \"class0\":{ \"locations\":[]},\n",
    "        \"class1\":{ \"locations\":[]}      \n",
    "    },\n",
    "    \"knn3\" : {\n",
    "        \"class0\":{ \"locations\":[]},\n",
    "        \"class1\":{ \"locations\":[]},\n",
    "        \"class2\":{ \"locations\":[]}\n",
    "    },\n",
    "    \"knn4\" : {\n",
    "        \"class0\":{ \"locations\":[]},\n",
    "        \"class1\":{ \"locations\":[]},\n",
    "        \"class2\":{ \"locations\":[]},\n",
    "        \"class3\":{ \"locations\":[]}, \n",
    "    },\n",
    "    \"knn5\" : {\n",
    "        \"class0\":{ \"locations\":[]},\n",
    "        \"class1\":{ \"locations\":[]},\n",
    "        \"class2\":{ \"locations\":[]}, \n",
    "        \"class3\":{ \"locations\":[]}, \n",
    "        \"class4\":{ \"locations\":[]} \n",
    "    },\n",
    "    \"knn6\" : {\n",
    "        \"class0\":{ \"locations\":[]},\n",
    "        \"class1\":{ \"locations\":[]},\n",
    "        \"class2\":{ \"locations\":[]},\n",
    "        \"class3\":{ \"locations\":[]}, \n",
    "        \"class4\":{ \"locations\":[]}, \n",
    "        \"class5\":{ \"locations\":[]}\n",
    "    },\n",
    "}\n",
    "\n",
    "kmeans_data4 =  {\n",
    "    \"knn2\" : {\n",
    "        \"data\":[],\n",
    "        \"mean0\":{},\n",
    "        \"mean1\":{}\n",
    "    },\n",
    "    \"knn3\" : {\n",
    "        \"data\":[],\n",
    "        \"mean0\":{},\n",
    "        \"mean1\":{},\n",
    "        \"mean2\":{}\n",
    "    },\n",
    "    \"knn4\" : {\n",
    "        \"data\":[],\n",
    "        \"mean0\":{},\n",
    "        \"mean1\":{},\n",
    "        \"mean2\":{},\n",
    "        \"mean3\":{}\n",
    "    },\n",
    "    \"knn5\" : {\n",
    "        \"data\":[],\n",
    "        \"mean0\":{},\n",
    "        \"mean1\":{} \n",
    "    },\n",
    "    \"knn6\" : {\n",
    "        \"data\":[],\n",
    "        \"mean0\":{},\n",
    "        \"mean1\":{},\n",
    "        \"mean2\":{},\n",
    "        \"mean3\":{},\n",
    "        \"mean4\":{},\n",
    "        \"mean5\":{},\n",
    "    },\n",
    "}\n",
    "\n",
    "for i,value in enumerate(kmeans_labels):\n",
    "    number_of_classes =  i+2\n",
    "    for x,class_nr in enumerate(kmeans_labels[i]):\n",
    "        kmeans_data3[\"knn{}\".format(number_of_classes)][\"class{}\".format(class_nr)][\"locations\"].append({\"lat\": location_input[x][0], \"lon\":location_input[x][1]})\n",
    "        kmeans_data4[\"knn{}\".format(number_of_classes)][\"data\"].append({\"lat\": location_input[x][0], \"lon\":location_input[x][1],\"class\":int(class_nr)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data2.json', 'w') as fp:\n",
    "    json.dump(kmeans_data4, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
