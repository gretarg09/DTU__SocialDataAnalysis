{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets start by getting the data\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "data = []\n",
    "\n",
    "def process(IncidntNum,Category,Descript,DayOfWeek,Data,Time,PdDistrict,Resolution,Address,X,Y,Location,PdId):\n",
    "    data.append({\n",
    "            \"IncidntNum\":IncidntNum,\n",
    "            \"Category\":Category,\n",
    "            \"Descript\":Descript,\n",
    "            \"DayOfWeek\":DayOfWeek,\n",
    "            \"Date\":Date,\n",
    "            \"Time\":Time,\n",
    "            \"PdDistrict\":PdDistrict,\n",
    "            \"Resolution\":Resolution,\n",
    "            \"Address\":Address,\n",
    "            \"X\":X,\n",
    "            \"Y\":Y,\n",
    "            \"Location\":Location,\n",
    "            \"PdId\":PdId})\n",
    "\n",
    "with open(\"SFPD_Incidents_-_from_1_January_2003.csv\", \"rb\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile,delimiter=\",\")\n",
    "    for row in reader:\n",
    "        IncidntNum = row[\"IncidntNum\"]\n",
    "        Category = row[\"Category\"]\n",
    "        Descript = row[\"Descript\"]\n",
    "        DayOfWeek = row[\"DayOfWeek\"]\n",
    "        Date = row[\"Date\"]\n",
    "        Time = row[\"Time\"]\n",
    "        PdDistrict = row[\"PdDistrict\"]\n",
    "        Resolution = row[\"Resolution\"]\n",
    "        Address = row[\"Address\"]\n",
    "        X = row[\"X\"]\n",
    "        Y = row[\"Y\"]\n",
    "        Location = row[\"Location\"]\n",
    "        PdId = row[\"PdId\"]\n",
    "        process(IncidntNum,Category,Descript,DayOfWeek,Date,Time,PdDistrict,Resolution,Address,X,Y,Location,PdId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_from_district(district_data, name):\n",
    "    nr_of_prostitution = len([line for line in district_data if line == \"PROSTITUTION\"])\n",
    "    nr_of_vehicle_theft = len([line for line in district_data if line == \"VEHICLE THEFT\"])\n",
    "    total_nr_of_crime = len(district_data)\n",
    "    return {\"District\":name, \"total\":total_nr_of_crime, \"vehicle\":nr_of_vehicle_theft, \"prostitution\":nr_of_prostitution}\n",
    "\n",
    "pdDistrict = set([line[\"PdDistrict\"] for line in data])\n",
    "    \n",
    "data_parsed = {\n",
    "    \"Period2003\":[],\n",
    "    \"Period2015\":[]\n",
    "}\n",
    "\n",
    "data_from_2015 = [{\"Category\":line[\"Category\"], \"PdDistrict\":line[\"PdDistrict\"]} for line in data if int(line[\"Date\"].split(\"/\")[-1]) == 2015]\n",
    "nr_of_crimes_2015 = len(data_from_2015)\n",
    "\n",
    "data_from_2003 = [{\"Category\":line[\"Category\"], \"PdDistrict\":line[\"PdDistrict\"]} for line in data if int(line[\"Date\"].split(\"/\")[-1]) == 2003]\n",
    "nr_of_crimes_2003 = len(data_from_2003)\n",
    " \n",
    "for district in pdDistrict:\n",
    "    data_for_district_2015 = [line[\"Category\"] for line in data_from_2015 if line[\"PdDistrict\"] == district]\n",
    "    data_parsed[\"Period2015\"].append(get_data_from_district(data_for_district_2015,district))\n",
    "    data_for_district_2003 = [line[\"Category\"] for line in data_from_2003 if line[\"PdDistrict\"] == district]\n",
    "    data_parsed[\"Period2003\"].append(get_data_from_district(data_for_district_2003,district))\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data1.json', 'w') as fp:\n",
    "    json.dump(data_parsed, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the data on correct format\n",
    "data_prostitution_location = {\n",
    "    \"lat\":[], \n",
    "    \"lon\":[] \n",
    "}\n",
    "\n",
    "for line in data:\n",
    "    if line[\"Category\"] == \"PROSTITUTION\":\n",
    "        latitute,longitute = line[\"Location\"].split(\",\")\n",
    "        latitute = float(latitute[1:])\n",
    "        longitute = float(longitute[:-1])\n",
    "        if float(latitute) < 90.00:\n",
    "            data_prostitution_location[\"lat\"].append(latitute)\n",
    "            data_prostitution_location[\"lon\"].append(longitute)\n",
    "\n",
    "kmeans_error = []\n",
    "kmeans_labels = []\n",
    "iterate = [i+2 for i in range(5)]\n",
    "\n",
    "# Get the data on correct format for sklearn.cluster.kmeans\n",
    "location_input = np.array(zip(data_prostitution_location[\"lat\"],data_prostitution_location[\"lon\"]))\n",
    "\n",
    "for i in iterate:\n",
    "    kMeans_ = KMeans(n_clusters=i, random_state=0).fit(location_input)\n",
    "    kmeans_error.append(kMeans_.inertia_)\n",
    "    kmeans_labels.append(kMeans_.labels_)\n",
    "    \n",
    "# Setup a dictionary\n",
    "kmeans_data =  {\n",
    "    \"knn2\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"knn3\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"knn4\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"knn5\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"knn6\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"locations\": []\n",
    "}\n",
    "\n",
    "# Go through all of the result of the knn model and insert the data into the predefined dictionary\n",
    "for i,value in enumerate(kmeans_labels):\n",
    "    number_of_classes =  i+2\n",
    "    for x,class_nr in enumerate(kmeans_labels[i]):\n",
    "        kmeans_data[\"knn{}\".format(number_of_classes)][\"data\"].append(int(class_nr))\n",
    "\n",
    "# Add the locations to the predefined dictionary\n",
    "kmeans_data[\"locations\"] = location_input.tolist()\n",
    "\n",
    "# Find the average lat and lon for each klass in each knn result\n",
    "# When I have calculated the mean for each class in each knn result I append the result to the data with the class 6\n",
    "#  Class 6 works as a Identifier for mean values in our javascript code\n",
    "for key in kmeans_data.keys():\n",
    "    if key is not \"locations\":\n",
    "        knn_classes = set(kmeans_data[key][\"data\"])\n",
    "        for knn_class in knn_classes:\n",
    "            #knn_class_as_string = \"class{}\".format(knn_class)\n",
    "            mean = np.mean([location for knn_class_,location in \n",
    "                 zip(kmeans_data[key][\"data\"],kmeans_data[\"locations\"]) if knn_class_ == knn_class],axis=0).tolist()\n",
    "            kmeans_data[key][\"data\"].append([knn_class,mean[0],mean[1]]) # I append additional row to the data with the class 6 \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data2.json', 'w') as fp:\n",
    "    json.dump(kmeans_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 37.7873942622172, -122.41721258128312],\n",
       " [1, 37.760004216651865, -122.41924311718498]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_data[\"knn2\"][\"data\"][16161:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37.78739426, -122.41721258])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([location for knn_class,location \n",
    "         in zip(kmeans_data[\"knn2\"][\"data\"],kmeans_data[\"locations\"]) if knn_class == 0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
