{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../data/SFPD_Incidents_-_from_1_January_2003.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b4d99c82437f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \"PdId\":PdId})\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/SFPD_Incidents_-_from_1_January_2003.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../data/SFPD_Incidents_-_from_1_January_2003.csv'"
     ]
    }
   ],
   "source": [
    "# lets start by getting the data\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "data = []\n",
    "\n",
    "def process(IncidntNum,Category,Descript,DayOfWeek,Data,Time,PdDistrict,Resolution,Address,X,Y,Location,PdId):\n",
    "    data.append({\n",
    "            \"IncidntNum\":IncidntNum,\n",
    "            \"Category\":Category,\n",
    "            \"Descript\":Descript,\n",
    "            \"DayOfWeek\":DayOfWeek,\n",
    "            \"Date\":Date,\n",
    "            \"Time\":Time,\n",
    "            \"PdDistrict\":PdDistrict,\n",
    "            \"Resolution\":Resolution,\n",
    "            \"Address\":Address,\n",
    "            \"X\":X,\n",
    "            \"Y\":Y,\n",
    "            \"Location\":Location,\n",
    "            \"PdId\":PdId})\n",
    "\n",
    "with open(\"SFPD_Incidents_-_from_1_January_2003.csv\", \"rb\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile,delimiter=\",\")\n",
    "    for row in reader:\n",
    "        IncidntNum = row[\"IncidntNum\"]\n",
    "        Category = row[\"Category\"]\n",
    "        Descript = row[\"Descript\"]\n",
    "        DayOfWeek = row[\"DayOfWeek\"]\n",
    "        Date = row[\"Date\"]\n",
    "        Time = row[\"Time\"]\n",
    "        PdDistrict = row[\"PdDistrict\"]\n",
    "        Resolution = row[\"Resolution\"]\n",
    "        Address = row[\"Address\"]\n",
    "        X = row[\"X\"]\n",
    "        Y = row[\"Y\"]\n",
    "        Location = row[\"Location\"]\n",
    "        PdId = row[\"PdId\"]\n",
    "        process(IncidntNum,Category,Descript,DayOfWeek,Date,Time,PdDistrict,Resolution,Address,X,Y,Location,PdId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The district_data parameter contains all datapoints for each district and the name parameter is the name of the corresponding district\n",
    "# The function calculates the total nr of crime in the district \n",
    "# The function also calculates the total number of vehicle theft observations and total number of prostitution observations in the district.\n",
    "def get_data_from_district(district_data, name):\n",
    "    nr_of_prostitution = len([line for line in district_data if line == \"PROSTITUTION\"])\n",
    "    nr_of_vehicle_theft = len([line for line in district_data if line == \"VEHICLE THEFT\"])\n",
    "    total_nr_of_crime = len(district_data)\n",
    "    return {\"District\":name, \"total\":total_nr_of_crime, \"vehicle\":nr_of_vehicle_theft, \"prostitution\":nr_of_prostitution}\n",
    "\n",
    "# Get the name of all PdDistrict in the dataset\n",
    "pdDistrict = set([line[\"PdDistrict\"] for line in data])\n",
    "\n",
    "# Creating dictionary to act as a container for the data\n",
    "data_parsed = {\n",
    "    \"Period2003\":[],\n",
    "    \"Period2015\":[]\n",
    "}\n",
    "\n",
    "# Get data from 2015\n",
    "data_from_2015 = [{\"Category\":line[\"Category\"], \"PdDistrict\":line[\"PdDistrict\"]} for line in data if int(line[\"Date\"].split(\"/\")[-1]) == 2015]\n",
    "nr_of_crimes_2015 = len(data_from_2015)\n",
    "\n",
    "# Get data from 2003\n",
    "data_from_2003 = [{\"Category\":line[\"Category\"], \"PdDistrict\":line[\"PdDistrict\"]} for line in data if int(line[\"Date\"].split(\"/\")[-1]) == 2003]\n",
    "nr_of_crimes_2003 = len(data_from_2003)\n",
    " \n",
    "# Go through all districts\n",
    "# The function get_data_from_district returns the total number of observations, total nr of prostitution observations and\n",
    "# the total nr of vehicle theft in the corresponding district. \n",
    "for district in pdDistrict:\n",
    "    data_for_district_2015 = [line[\"Category\"] for line in data_from_2015 if line[\"PdDistrict\"] == district]\n",
    "    data_parsed[\"Period2015\"].append(get_data_from_district(data_for_district_2015,district))\n",
    "    data_for_district_2003 = [line[\"Category\"] for line in data_from_2003 if line[\"PdDistrict\"] == district]\n",
    "    data_parsed[\"Period2003\"].append(get_data_from_district(data_for_district_2003,district))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating json file for visualization 1 to import into our javascript code\n",
    "import json\n",
    "with open('data1.json', 'w') as fp:\n",
    "    json.dump(data_parsed, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create dictionary to act as a container for the location of each prostitute observation\n",
    "data_prostitution_location = {\n",
    "    \"lat\":[], \n",
    "    \"lon\":[] \n",
    "}\n",
    "\n",
    "# Get location of each prostitution observation\n",
    "for line in data:\n",
    "    if line[\"Category\"] == \"PROSTITUTION\":\n",
    "        latitute,longitute = line[\"Location\"].split(\",\")\n",
    "        latitute = float(latitute[1:])\n",
    "        longitute = float(longitute[:-1])\n",
    "        if float(latitute) < 90.00:\n",
    "            data_prostitution_location[\"lat\"].append(latitute)\n",
    "            data_prostitution_location[\"lon\"].append(longitute)\n",
    "\n",
    "kmeans_error = []\n",
    "kmeans_labels = []\n",
    "iterate = [i+2 for i in range(5)]\n",
    "\n",
    "# Get the data on correct format for sklearn.cluster.kmeans\n",
    "location_input = np.array(zip(data_prostitution_location[\"lat\"],data_prostitution_location[\"lon\"]))\n",
    "\n",
    "# Create five different kmeans models (kmeans2,kmeans3,kmeans4,kmeans5,kmeans6) and save the errors and labels of each model\n",
    "for i in iterate:\n",
    "    kMeans_ = KMeans(n_clusters=i, random_state=0).fit(location_input)\n",
    "    kmeans_error.append(kMeans_.inertia_)\n",
    "    kmeans_labels.append(kMeans_.labels_)\n",
    "    \n",
    "# Setup a dictionary\n",
    "kmeans_data =  {\n",
    "    \"kmeans2\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"kmeans3\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"kmeans4\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"kmeans5\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"kmeans6\" : {\n",
    "        \"data\":[]\n",
    "    },\n",
    "    \"locations\": []\n",
    "}\n",
    "\n",
    "# Go through the result of the kmeans model and insert the data into the predefined dictionary\n",
    "for i,value in enumerate(kmeans_labels):\n",
    "    number_of_classes =  i+2\n",
    "    for x,class_nr in enumerate(kmeans_labels[i]):\n",
    "        kmeans_data[\"kmeans{}\".format(number_of_classes)][\"data\"].append(int(class_nr))\n",
    "\n",
    "# Add the locations to the predefined dictionary\n",
    "kmeans_data[\"locations\"] = location_input.tolist()\n",
    "\n",
    "# Find the average lat and lon for each klass in each kmeans result\n",
    "# When I have calculated the mean for each class in each kmeans model result I append the result to the data \n",
    "# The format of the appended mean data is as follows: [class,lat,lon]\n",
    "for key in kmeans_data.keys():\n",
    "    if key is not \"locations\":\n",
    "        kmeans_classes = set(kmeans_data[key][\"data\"])\n",
    "        for kmeans_class in kmeans_classes:\n",
    "            #kmeans_class_as_string = \"class{}\".format(kmeans_class)\n",
    "            mean = np.mean([location for kmeans_class_,location in \n",
    "                 zip(kmeans_data[key][\"data\"],kmeans_data[\"locations\"]) if kmeans_class_ == kmeans_class],axis=0).tolist()\n",
    "            kmeans_data[key][\"data\"].append([kmeans_class,mean[0],mean[1]]) # I append additional row to the data with the class 6 \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating json file for visualization 2 to import into our javascript code\n",
    "import json\n",
    "with open('data2.json', 'w') as fp:\n",
    "    json.dump(kmeans_data, fp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
